{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import All libraries \n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import optuna\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytorch_metric_learning.losses import SupConLoss\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image transformations (including normalization)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load the full MNIST training set\n",
    "full_train_data = datasets.MNIST(root=\"D:\\MNIST\\MNIST_Train\", train=True, download=False, transform=transform)\n",
    "test_data = datasets.MNIST(root=\"D:\\MNIST\\MNIST_Test\", train=False, download=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the Train-Test Split \n",
    "torch.manual_seed(42) \n",
    "\n",
    "train_size = int(0.8 * len(full_train_data))  \n",
    "val_size = len(full_train_data) - train_size  \n",
    "\n",
    "# Split the full training dataset\n",
    "train_data, val_data = random_split(full_train_data, [train_size, val_size])\n",
    "\n",
    "# Load the training and validation data\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "\n",
    "# Test data\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNEncoder(nn.Module): #Encoder as we're only interest in the final embedding provided by the CNN \n",
    "    def __init__(self):\n",
    "        super(CNNEncoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.fc = nn.Linear(256 * 7 * 7, 128)  # Output: 128-dimension embeddings\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)  # 14x14\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)  # 7x7\n",
    "        \n",
    "        x = x.view(-1, 256 * 7 * 7)  # Flatten\n",
    "        x = self.fc(x)  # Output embeddings\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(128, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'faiss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rodri\\Desktop\\MEMEC - 2ÂºAno\\Sistemas Inteligentes\\Project\\SupervisedContrastiveLoss.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rodri/Desktop/MEMEC%20-%202%C2%BAAno/Sistemas%20Inteligentes/Project/SupervisedContrastiveLoss.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m contrastive_loss \u001b[39m=\u001b[39m SupConLoss()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rodri/Desktop/MEMEC%20-%202%C2%BAAno/Sistemas%20Inteligentes/Project/SupervisedContrastiveLoss.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Initialize accuracy calculator\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rodri/Desktop/MEMEC%20-%202%C2%BAAno/Sistemas%20Inteligentes/Project/SupervisedContrastiveLoss.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m ccuracy_calculator \u001b[39m=\u001b[39m AccuracyCalculator(include\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mprecision_at_1\u001b[39;49m\u001b[39m\"\u001b[39;49m,), knn_func\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rodri/Desktop/MEMEC%20-%202%C2%BAAno/Sistemas%20Inteligentes/Project/SupervisedContrastiveLoss.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mContrastiveTrainer\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rodri/Desktop/MEMEC%20-%202%C2%BAAno/Sistemas%20Inteligentes/Project/SupervisedContrastiveLoss.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, encoder, classifier, criterion, optimizer):\n",
      "File \u001b[1;32mc:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_metric_learning\\utils\\accuracy_calculator.py:239\u001b[0m, in \u001b[0;36mAccuracyCalculator.__init__\u001b[1;34m(self, include, exclude, avg_of_avgs, return_per_class, k, label_comparison_fn, device, knn_func, kmeans_func)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_per_class \u001b[39m=\u001b[39m return_per_class\n\u001b[0;32m    238\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m c_f\u001b[39m.\u001b[39muse_cuda_if_available() \u001b[39mif\u001b[39;00m device \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m device\n\u001b[1;32m--> 239\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mknn_func \u001b[39m=\u001b[39m FaissKNN() \u001b[39mif\u001b[39;00m knn_func \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m knn_func\n\u001b[0;32m    240\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkmeans_func \u001b[39m=\u001b[39m (\n\u001b[0;32m    241\u001b[0m     FaissKMeans(niter\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, gpu\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    242\u001b[0m     \u001b[39mif\u001b[39;00m kmeans_func \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     \u001b[39melse\u001b[39;00m kmeans_func\n\u001b[0;32m    244\u001b[0m )\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(k, \u001b[39mint\u001b[39m) \u001b[39mand\u001b[39;00m k \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)) \u001b[39mand\u001b[39;00m (k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mmax_bin_count\u001b[39m\u001b[39m\"\u001b[39m]):\n",
      "File \u001b[1;32mc:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_metric_learning\\utils\\inference.py:160\u001b[0m, in \u001b[0;36mFaissKNN.__init__\u001b[1;34m(self, reset_before, reset_after, index_init_fn, gpus)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_before \u001b[39m=\u001b[39m reset_before\n\u001b[0;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_after \u001b[39m=\u001b[39m reset_after\n\u001b[0;32m    159\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex_init_fn \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 160\u001b[0m     faiss\u001b[39m.\u001b[39mIndexFlatL2 \u001b[39mif\u001b[39;00m index_init_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m index_init_fn\n\u001b[0;32m    161\u001b[0m )\n\u001b[0;32m    162\u001b[0m \u001b[39mif\u001b[39;00m gpus \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(gpus, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'faiss' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the Supervised Contrastive Loss from the library\n",
    "contrastive_loss = SupConLoss()\n",
    "\n",
    "# Initialize accuracy calculator\n",
    "ccuracy_calculator = AccuracyCalculator(include=(\"precision_at_1\",), knn_func=None)\n",
    "\n",
    "class ContrastiveTrainer:\n",
    "    def __init__(self, encoder, classifier, criterion, optimizer):\n",
    "        self.encoder = encoder\n",
    "        self.classifier = classifier\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def train_contrastive(self, train_loader, epochs=10):\n",
    "        self.encoder.train()\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass through the encoder\n",
    "                features = self.encoder(images)\n",
    "\n",
    "                # Compute supervised contrastive loss\n",
    "                loss = self.criterion(features, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Contrastive Loss: {total_loss / len(train_loader):.4f}')\n",
    "    \n",
    "    def train_classifier(self, train_loader, epochs=5):\n",
    "        self.encoder.eval()  # Freeze the encoder for classifier training\n",
    "        self.classifier.train()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            correct = 0\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # Extract frozen features\n",
    "                with torch.no_grad():\n",
    "                    features = self.encoder(images)\n",
    "\n",
    "                # Forward pass through the classifier\n",
    "                outputs = self.classifier(features)\n",
    "                loss = F.cross_entropy(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            accuracy = correct / len(train_loader.dataset)\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Classification Loss: {total_loss / len(train_loader):.4f}, Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "    def evaluate_embeddings(self, test_loader):\n",
    "        self.encoder.eval()\n",
    "        all_embeddings = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                features = self.encoder(images)\n",
    "                \n",
    "                all_embeddings.append(features.cpu())\n",
    "                all_labels.append(labels.cpu())\n",
    "\n",
    "        all_embeddings = torch.cat(all_embeddings)\n",
    "        all_labels = torch.cat(all_labels)\n",
    "\n",
    "        print(accuracy_calculator.get_accuracy(all_embeddings, all_labels, all_embeddings, all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize encoder, classifier, and optimizer\n",
    "contrastive_loss = SupConLoss().to(device)\n",
    "encoder = CNNEncoder().to(device)\n",
    "classifier = MLPClassifier().to(device)\n",
    "\n",
    "# Use Adam optimizer for both contrastive learning and classification\n",
    "optimizer = torch.optim.Adam(list(encoder.parameters()) + list(classifier.parameters()), lr=0.001)\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = ContrastiveTrainer(encoder, classifier, contrastive_loss, optimizer)\n",
    "\n",
    "# 1. Train the encoder with Supervised Contrastive Learning\n",
    "trainer.train_contrastive(train_loader, epochs=10)\n",
    "\n",
    "# 2. Fine-tune the classifier on top of the frozen encoder\n",
    "trainer.train_classifier(train_loader, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1rc1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1rc1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98b9776bb1c906ffea5885633daef92fdfff9bdc53a036d784e355cfb10fec4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
