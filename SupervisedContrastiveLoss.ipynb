{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import All libraries \n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import optuna\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytorch_metric_learning.losses import SupConLoss\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define image transformations (including normalization)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load the full MNIST training set\n",
    "full_train_data = datasets.MNIST(root=\"D:\\MNIST\\MNIST_Train\", train=True, download=False, transform = transform)\n",
    "test_data = datasets.MNIST(root=\"D:\\MNIST\\MNIST_Test\", train=False, download=False, transform= transform)\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "torch.manual_seed(42)  # You can choose any seed number\n",
    "\n",
    "# Define train-validation split sizes\n",
    "train_size = int(0.8 * len(full_train_data))  # 80% for training\n",
    "val_size = len(full_train_data) - train_size  # 20% for validation\n",
    "\n",
    "# Split the full training dataset\n",
    "train_data, val_data = random_split(full_train_data, [train_size, val_size])\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNEncoder(nn.Module): #Encoder as we're only interest in the final embedding provided by the CNN \n",
    "    def __init__(self):\n",
    "        super(CNNEncoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.fc = nn.Linear(256 * 7 * 7, 128)  # Output: 128-dimension embeddings\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)  # 14x14\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)  # 7x7\n",
    "        \n",
    "        x = x.view(-1, 256 * 7 * 7)  # Flatten\n",
    "        x = self.fc(x)  # Output embeddings\n",
    "        return x\n",
    "\n",
    "class MLPClassifier(nn.Module): # MLP projection Head \n",
    "    def __init__(self):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(128, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize accuracy calculator\n",
    "#accuracy_calculator = AccuracyCalculator(include=(\"precision_at_1\",), knn_func=None)\n",
    "\n",
    "class ContrastiveTrainer:\n",
    "    def __init__(self, encoder, classifier, criterion, optimizer):\n",
    "        self.encoder = encoder\n",
    "        self.classifier = classifier\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def train_contrastive(self, train_loader, epochs=10):\n",
    "        self.encoder.train()\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass through the encoder\n",
    "                features = self.encoder(images)\n",
    "\n",
    "                # Compute supervised contrastive loss\n",
    "                loss = self.criterion(features, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Contrastive Loss: {total_loss / len(train_loader):.4f}')\n",
    "    \n",
    "    def train_classifier(self, train_loader, epochs=5):\n",
    "        self.encoder.eval()  # Freeze the encoder for classifier training\n",
    "        self.classifier.train()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            correct = 0\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # Extract frozen features\n",
    "                with torch.no_grad():\n",
    "                    features = self.encoder(images)\n",
    "\n",
    "                # Forward pass through the classifier\n",
    "                outputs = self.classifier(features)\n",
    "                loss = F.cross_entropy(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            accuracy = correct / len(train_loader.dataset)\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Classification Loss: {total_loss / len(train_loader):.4f}, Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "   # def evaluate_embeddings(self, test_loader):\n",
    "    #    self.encoder.eval()\n",
    "   #     all_embeddings = []\n",
    "  #      all_labels = []\n",
    "#\n",
    "  #      with torch.no_grad():\n",
    "     #       for images, labels in test_loader:\n",
    "    #            images, labels = images.to(device), labels.to(device)\n",
    "      #          features = self.encoder(images)\n",
    "      #          \n",
    "       #         all_embeddings.append(features.cpu())\n",
    "       #         all_labels.append(labels.cpu())\n",
    "#\n",
    "        #all_embeddings = torch.cat(all_embeddings)\n",
    "       # all_labels = torch.cat(all_labels)\n",
    "\n",
    "       # print(accuracy_calculator.get_accuracy(all_embeddings, all_labels, all_embeddings, all_labels))\n",
    "\n",
    "    def test_classifier(self, test_loader):\n",
    "            self.encoder.eval()\n",
    "            self.classifier.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in test_loader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    features = self.encoder(images)\n",
    "                    outputs = self.classifier(features)\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning with Optuna\n",
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_int('batch_size', 32, 128, step=32)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    encoder = CNNEncoder().to(device)\n",
    "    classifier = MLPClassifier().to(device)\n",
    "    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(classifier.parameters()), lr=lr)\n",
    "    contrastive_loss = SupConLoss().to(device)\n",
    "    \n",
    "    trainer = ContrastiveTrainer(encoder, classifier, contrastive_loss, optimizer)\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train_contrastive(train_loader, epochs=5)  # Train for fewer epochs for tuning speed\n",
    "    trainer.train_classifier(train_loader, epochs=3)\n",
    "    \n",
    "    # Evaluate on validation data\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            features = encoder(images)\n",
    "            outputs = classifier(features)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-14 20:07:15,696] A new study created in memory with name: no-name-35755f62-4af1-4178-9c11-820e4e543cb1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Contrastive Loss: 2.1345\n",
      "Epoch [2/5], Contrastive Loss: 1.8888\n",
      "Epoch [3/5], Contrastive Loss: 1.8504\n",
      "Epoch [4/5], Contrastive Loss: 1.8356\n",
      "Epoch [5/5], Contrastive Loss: 1.8225\n",
      "Epoch [1/3], Classification Loss: 0.3540, Accuracy: 99.24%\n",
      "Epoch [2/3], Classification Loss: 0.1595, Accuracy: 99.58%\n",
      "Epoch [3/3], Classification Loss: 0.1152, Accuracy: 99.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-14 20:53:38,226] Trial 0 finished with value: 0.9903333333333333 and parameters: {'lr': 0.0028423379696248395, 'batch_size': 64}. Best is trial 0 with value: 0.9903333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Contrastive Loss: 2.5477\n",
      "Epoch [2/5], Contrastive Loss: 2.3206\n",
      "Epoch [3/5], Contrastive Loss: 2.2879\n",
      "Epoch [4/5], Contrastive Loss: 2.2679\n",
      "Epoch [5/5], Contrastive Loss: 2.2531\n",
      "Epoch [1/3], Classification Loss: 28.6041, Accuracy: 99.07%\n",
      "Epoch [2/3], Classification Loss: 15.5110, Accuracy: 99.33%\n",
      "Epoch [3/3], Classification Loss: 16.8351, Accuracy: 99.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-14 21:35:52,802] Trial 1 finished with value: 0.9841666666666666 and parameters: {'lr': 0.008118565729670381, 'batch_size': 96}. Best is trial 0 with value: 0.9903333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'lr': 0.0028423379696248395, 'batch_size': 64}\n"
     ]
    }
   ],
   "source": [
    "# Run Optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=2)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(\"Best hyperparameters: \", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Contrastive Loss: 2.1586\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rodri\\Desktop\\MEMEC - 2ºAno\\Sistemas Inteligentes\\Project\\SupervisedContrastiveLoss.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rodri/Desktop/MEMEC%20-%202%C2%BAAno/Sistemas%20Inteligentes/Project/SupervisedContrastiveLoss.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m trainer \u001b[39m=\u001b[39m ContrastiveTrainer(encoder, classifier, contrastive_loss, optimizer)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rodri/Desktop/MEMEC%20-%202%C2%BAAno/Sistemas%20Inteligentes/Project/SupervisedContrastiveLoss.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Final training and testing\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/rodri/Desktop/MEMEC%20-%202%C2%BAAno/Sistemas%20Inteligentes/Project/SupervisedContrastiveLoss.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain_contrastive(train_loader, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rodri/Desktop/MEMEC%20-%202%C2%BAAno/Sistemas%20Inteligentes/Project/SupervisedContrastiveLoss.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m trainer\u001b[39m.\u001b[39mtrain_classifier(train_loader, epochs\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rodri/Desktop/MEMEC%20-%202%C2%BAAno/Sistemas%20Inteligentes/Project/SupervisedContrastiveLoss.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m trainer\u001b[39m.\u001b[39mtest_classifier(test_loader)\n",
      "\u001b[1;32mc:\\Users\\rodri\\Desktop\\MEMEC - 2ºAno\\Sistemas Inteligentes\\Project\\SupervisedContrastiveLoss.ipynb Cell 7\u001b[0m in \u001b[0;36mContrastiveTrainer.train_contrastive\u001b[1;34m(self, train_loader, epochs)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rodri/Desktop/MEMEC%20-%202%C2%BAAno/Sistemas%20Inteligentes/Project/SupervisedContrastiveLoss.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Compute supervised contrastive loss\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rodri/Desktop/MEMEC%20-%202%C2%BAAno/Sistemas%20Inteligentes/Project/SupervisedContrastiveLoss.ipynb#W6sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(features, labels)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/rodri/Desktop/MEMEC%20-%202%C2%BAAno/Sistemas%20Inteligentes/Project/SupervisedContrastiveLoss.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rodri/Desktop/MEMEC%20-%202%C2%BAAno/Sistemas%20Inteligentes/Project/SupervisedContrastiveLoss.ipynb#W6sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rodri/Desktop/MEMEC%20-%202%C2%BAAno/Sistemas%20Inteligentes/Project/SupervisedContrastiveLoss.ipynb#W6sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Use best hyperparameters to train the final model\n",
    "best_params = study.best_params\n",
    "train_loader = DataLoader(train_data, batch_size=best_params['batch_size'], shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=best_params['batch_size'], shuffle=False)\n",
    "\n",
    "# \n",
    "encoder = CNNEncoder().to(device)\n",
    "classifier = MLPClassifier().to(device)\n",
    "optimizer = torch.optim.Adam(list(encoder.parameters()) + list(classifier.parameters()), lr=best_params['lr'])\n",
    "contrastive_loss = SupConLoss().to(device)\n",
    "\n",
    "\n",
    "trainer = ContrastiveTrainer(encoder, classifier, contrastive_loss, optimizer)\n",
    "\n",
    "# Final training and testing\n",
    "trainer.train_contrastive(train_loader, epochs=10)\n",
    "trainer.train_classifier(train_loader, epochs=5)\n",
    "trainer.test_classifier(test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1rc1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1rc1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98b9776bb1c906ffea5885633daef92fdfff9bdc53a036d784e355cfb10fec4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
